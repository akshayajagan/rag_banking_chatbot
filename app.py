# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G7f2JKKzzSWrZuDBg67HixbgOooHi9jl
"""

import os

import logging

pip install streamlit

import os
import logging
import streamlit as st
import time
import soundfile as sf

pip install kokoro

pip install fasttext

pip install Groq

pip install gTTS

pip install googletrans

import io

import os
import logging
import streamlit as st
import time
import soundfile as sf
from kokoro import KPipeline
import numpy as np
import fasttext
from groq import Groq
from gtts import gTTS
from googletrans import Translator, LANGUAGES
import io

logging.basicConfig(level=logging.INFO)

logger = logging.getLogger(__name__)

GROQ_API_KEY = "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"

!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin

try:
    lang_model = fasttext.load_model("lid.176.bin")
except Exception as e:
    logger.error(f"Failed to load fasttext model: {e}")
    lang_model = None

BANKING_INFO = {
    "savings account": "To open a savings account, you need to provide ID proof, address proof, and fill out an application form. Visit your nearest branch or apply online.",
    "loan": "To apply for a personal loan, submit income proof, credit history, and ID documents. Interest rates start at 5% per annum.",
    "credit card": "Our credit cards offer cashback, reward points, and no annual fees for the first year.",
    "online banking": "Access your account 24/7, transfer funds, pay bills, and check balances through our secure portal.",
    "kyc": "To complete KYC, submit a valid ID proof (e.g., passport, driver's license), address proof (e.g., utility bill), and a recent photograph. You can do this online or at a branch.",
    "upi": "To activate UPI (Unified Payments Interface), follow these steps:\n1. Install a UPI-supported app on your smartphone, such as BHIM, Google Pay, PhonePe, or Paytm.\n2. Register using your bank account number and IFSC code, and complete the KYC process.\n3. Set a UPI PIN by following the instructions within the app. The PIN will be required for all transactions.\n4. Once the registration and KYC processes are complete, your UPI ID will be generated using your mobile number in the format [yourmobilenumber]@upi. Your UPI account is now active, and you can start making payments and receiving money.\nFor specific instructions, please refer to the user manual or customer support of the UPI app you have chosen. If you have any trouble, feel free to ask for further assistance."
}

KOKORO_LANGUAGES = {"en": "en_heart", "fr": "fr_heart", "es": "es_heart"}
GTTS_LANGUAGES = {"ta": "ta", "te": "te", "hi": "hi"}

translator = Translator()

def detect_language(text):
    if not lang_model:
        logger.warning("Fasttext model not loaded. Assuming English.")
        return "en"
    try:
        prediction = lang_model.predict(text)
        lang = prediction[0][0].split("_label")[1].split("")[0]
        confidence = prediction[1][0]
        logger.info(f"Detected language: {lang} (confidence: {confidence:.2f})")
        return lang
    except Exception as e:
        logger.error(f"Language detection failed: {e}")
        return "en"

def translate_text(text, src_lang, dest_lang):
    try:
        max_chunk_length = 500  # Avoid googletrans length limits
        chunks = [text[i:i + max_chunk_length] for i in range(0, len(text), max_chunk_length)]
        translated_chunks = []
        for chunk in chunks:
            translated = translator.translate(chunk, src=src_lang, dest=dest_lang)
            translated_chunks.append(translated.text)
            time.sleep(1)  # Avoid rate limits
        translated_text = "".join(translated_chunks)
        logger.info(f"Translated from {src_lang} to {dest_lang}: {translated_text[:50]}...")
        return translated_text
    except Exception as e:
        logger.error(f"Translation error from {src_lang} to {dest_lang}: {e}")
        return text

def find_relevant_info(query):
    query = query.lower()
    query_words = query.split()
    for key, value in BANKING_INFO.items():
        if key in query:  # Exact match
            logger.info(f"Found exact match for key: {key}")
            return value
        # Partial match: check if any query word matches the key
        for word in query_words:
            if word in key:
                logger.info(f"Found partial match for key: {key} with word: {word}")
                return value
    logger.warning("No relevant info found in knowledge base.")
    return None

def query_llm(prompt):
    logger.info("Attempting to use Groq API with LLaMA model")
    try:
        client = Groq(api_key=GROQ_API_KEY)
        response = client.chat.completions.create(
            model="mistral-saba-24b",
            messages=[
                {"role": "system", "content": "You are a friendly and helpful banking assistant."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,  # Increased to handle longer responses
            temperature=0.7
        )
        generated_text = response.choices[0].message.content.strip()
        logger.info(f"Groq API response: {generated_text}")
        return generated_text
    except Exception as e:
        logger.error(f"Groq API error: {e}")
        logger.warning("Falling back to default response")
        return None

def generate_kokoro_speech(text, lang_code, voice):
    logger.info(f"Generating speech with Kokoro-82M for text: {text[:50]}... (lang: {lang_code})")
    try:
        pipeline = KPipeline(lang_code=lang_code)
        generator = pipeline(text, voice=voice)
        audio_chunks = []
        for i, (gs, ps, audio) in enumerate(generator):
            logger.info(f"Processing audio chunk {i}: gs={gs}, ps={ps}, audio_shape={audio.shape}")
            audio_chunks.append(audio)
        if not audio_chunks:
            logger.warning("No audio chunks generated by Kokoro-82M")
            return None
        full_audio = np.concatenate(audio_chunks, axis=0)
        temp_audio_path = "temp_audio.wav"
        sf.write(temp_audio_path, full_audio, 24000)
        with open(temp_audio_path, "rb") as f:
            audio_bytes = f.read()
        os.remove(temp_audio_path)
        logger.info(f"Kokoro-82M audio generation successful, size: {len(audio_bytes)} bytes")
        return audio_bytes
    except Exception as e:
        logger.error(f"Kokoro-82M TTS error: {e}")
        return None

def generate_gtts_speech(text, lang_code):
    logger.info(f"Generating speech with gTTS for text: {text[:50]}... (lang: {lang_code})")
    try:
        tts = gTTS(text=text, lang=lang_code, slow=False)
        temp_audio_path = "temp_audio.mp3"
        tts.save(temp_audio_path)
        with open(temp_audio_path, "rb") as f:
            audio_bytes = f.read()
        os.remove(temp_audio_path)
        logger.info(f"gTTS audio generation successful, size: {len(audio_bytes)} bytes")
        return audio_bytes
    except Exception as e:
        logger.error(f"gTTS error: {e}")
        return None

def generate_speech(text, lang):
    if not text:
        logger.error("Empty text provided to speech generator")
        return None
    if lang in KOKORO_LANGUAGES:
        return generate_kokoro_speech(text, lang_code=lang, voice=KOKORO_LANGUAGES[lang])
    elif lang in GTTS_LANGUAGES:
        return generate_gtts_speech(text, lang_code=GTTS_LANGUAGES[lang])
    else:
        logger.warning(f"Language {lang} not supported for TTS, defaulting to English (Kokoro)")
        return generate_kokoro_speech(text, lang_code="en", voice="en_heart")

def banking_chatbot(query):
    logger.info(f"Processing query: {query}")

    # Detect language
    lang = detect_language(query)
    logger.info(f"Detected language: {lang}")

    # If language is not supported, return a message in English
    if lang not in KOKORO_LANGUAGES and lang not in GTTS_LANGUAGES:
        text_response = "Hi! I currently support English, French, Spanish, Tamil, Telugu, and Hindi. Please ask your question in one of these languages."
        audio = generate_speech(text_response, "en")
        return text_response, audio

    # Translate query to English if not already in English
    query_in_english = query
    if lang != "en":
        query_in_english = translate_text(query, src_lang=lang, dest_lang="en")
        logger.info(f"Translated query to English: {query_in_english}")

    # Find relevant banking information
    relevant_info = find_relevant_info(query_in_english)
    logger.info(f"Relevant info found: {relevant_info}")

    # Prepare prompt for LLM
    if relevant_info:
        context = f"Relevant information: {relevant_info}"
    else:
        context = "You are a banking assistant. Answer the question to the best of your ability."

    prompt = (
        f"<s>[INST] You are a friendly and helpful banking assistant.\n"
        f"{context}\n\nUser query: {query_in_english}\n"
        f"Provide a helpful, concise response.[/INST]"
    )
    text_response = query_llm(prompt)
    logger.info(f"LLM response (English): {text_response}")
     # Fallback responses
    if not text_response:
        if query_in_english.lower() == "hi":
            text_response = "Hello! How can I assist you with your banking needs today?"
        elif relevant_info:
            text_response = relevant_info
        else:
            text_response = "I'm sorry, I'm having trouble connecting to my knowledge base right now. Please try again in a moment or check available models at https://console.groq.com."

    if not text_response.startswith("Hi") and not text_response.startswith("Hello"):
        text_response = f"Hi! {text_response}"

    # Translate response back to original language if not English
    if lang != "en":
        text_response = translate_text(text_response, src_lang="en", dest_lang=lang)
        logger.info(f"Translated response to {lang}: {text_response}")

    logger.info(f"Final response: {text_response}")

    audio = generate_speech(text_response, lang)

    if not audio or len(audio) < 100:
        logger.warning("TTS failed or returned minimal data, returning text response only")

    return text_response, audio

# Streamlit UI with improved rendering
def main():
    st.set_page_config(page_title="Friendly Banking Chatbot", page_icon="💬")
    st.title("Banking Chatbot")
    st.markdown("Ask me anything about banking in English, French, Spanish, Tamil, Telugu, or Hindi!")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            # Ensure full text is visible with scrollable container
            st.markdown(
                f'<div style="max-height: 200px; overflow-y: auto;">{msg["content"]}</div>',
                unsafe_allow_html=True
            )
            if msg["role"] == "assistant" and "audio" in msg and msg["audio"]:
                st.audio(msg["audio"], format="audio/wav" if msg["lang"] in KOKORO_LANGUAGES else "audio/mp3")

    query = st.chat_input("Type your banking question here...")
    if query:
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"):
            st.markdown(
                f'<div style="max-height: 200px; overflow-y: auto;">{query}</div>',
                unsafe_allow_html=True
            )

        with st.spinner("Thinking..."):
            response, audio = banking_chatbot(query)
            lang = detect_language(query)

        st.session_state.messages.append({"role": "assistant", "content": response, "audio": audio, "lang": lang})

        with st.chat_message("assistant"):
            st.markdown(
                f'<div style="max-height: 200px; overflow-y: auto;">{response}</div>',
                unsafe_allow_html=True
            )
            if audio:
                audio_format = "audio/wav" if lang in KOKORO_LANGUAGES else "audio/mp3"
                st.audio(audio, format=audio_format)
            else:
                st.warning("Audio generation failed, but here's the text response.")

if __name__== "_main_":
    main()

pip install faiss-cpu sentence-transformers

from sentence_transformers import SentenceTransformer
import faiss

# Initialize embedding model
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

# Sample documents for RAG
DOCUMENTS = [
    "To open a savings account, provide your ID, address proof, and fill a form. Visit a branch or apply online.",
    "For a personal loan, submit income proof, credit history, and ID documents. Interest rates start at 5% p.a.",
    "Our credit cards offer cashback, rewards, and no annual fees in year one.",
    "Use online banking to check balances, transfer money, and pay bills 24/7 securely.",
    "KYC requires valid ID, address proof, and a recent photo, either online or at a branch.",
    "To activate UPI, install an app like PhonePe or GPay, complete KYC, and set your UPI PIN."
]

# Precompute document embeddings
doc_embeddings = embedding_model.encode(DOCUMENTS, convert_to_tensor=False)
index = faiss.IndexFlatL2(doc_embeddings[0].shape[0])
index.add(np.array(doc_embeddings))

# Function to retrieve relevant documents
def retrieve_docs_rag(query, k=2):
    query_embedding = embedding_model.encode([query])[0]
    D, I = index.search(np.array([query_embedding]), k)
    retrieved_docs = [DOCUMENTS[i] for i in I[0]]
    logger.info(f"RAG Retrieved Docs: {retrieved_docs}")
    return retrieved_docs

